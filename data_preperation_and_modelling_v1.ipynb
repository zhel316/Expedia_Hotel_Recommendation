{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the data  (4958347, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      NaN                   NaN              219      893   \n",
       "1                      NaN                   NaN              219    10404   \n",
       "2                      NaN                   NaN              219    21315   \n",
       "3                      NaN                   NaN              219    27348   \n",
       "4                      NaN                   NaN              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  comp6_rate_percent_diff  \\\n",
       "0                3                3.5  ...                      NaN   \n",
       "1                4                4.0  ...                      NaN   \n",
       "2                3                4.5  ...                      NaN   \n",
       "3                2                4.0  ...                      NaN   \n",
       "4                4                3.5  ...                      NaN   \n",
       "\n",
       "   comp7_rate  comp7_inv  comp7_rate_percent_diff  comp8_rate  comp8_inv  \\\n",
       "0         NaN        NaN                      NaN         0.0        0.0   \n",
       "1         NaN        NaN                      NaN         0.0        0.0   \n",
       "2         NaN        NaN                      NaN         0.0        0.0   \n",
       "3         NaN        NaN                      NaN        -1.0        0.0   \n",
       "4         NaN        NaN                      NaN         0.0        0.0   \n",
       "\n",
       "   comp8_rate_percent_diff  click_bool  gross_bookings_usd  booking_bool  \n",
       "0                      NaN           0                 NaN             0  \n",
       "1                      NaN           0                 NaN             0  \n",
       "2                      NaN           0                 NaN             0  \n",
       "3                      5.0           0                 NaN             0  \n",
       "4                      NaN           0                 NaN             0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/training_set_VU_DM.csv')\n",
    "print(\"the shape of the data \",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_zscore(df, columns, threshold=0.5):\n",
    "    # Calculate the z-scores for the specified columns\n",
    "    z_scores = df[columns].apply(lambda x: (x - x.mean()) / x.std())\n",
    "    \n",
    "    # Identify the rows containing outliers based on the threshold\n",
    "    outlier_rows = z_scores.abs().apply(lambda x: any(abs(val) > threshold for val in x), axis=1)\n",
    "    \n",
    "    # Get the outliers and the cleaned DataFrame\n",
    "    outliers = df[outlier_rows]\n",
    "    df_cleaned = df[~outlier_rows]\n",
    "    \n",
    "    return df_cleaned, outliers\n",
    "\n",
    "columns = ['price_usd','comp3_rate_percent_diff',\n",
    "            'comp8_rate_percent_diff','comp5_rate_percent_diff','comp4_rate_percent_diff']\n",
    "\n",
    "cleaned_df, outliers = remove_outliers_zscore(df, columns, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/l2pgxhp51rs57jb2mpt6g5vc0000gn/T/ipykernel_20645/3780794415.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column].fillna(df[\"prop_country_id\"].map(first_quartile_by_country), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# to fill the missing value with first quartile\n",
    "def fill_missing_values_with_first_quartile(df, columns_to_fill):\n",
    "    # Loop through each column and fill missing values with the first quartile of the respective country\n",
    "    for column in columns_to_fill:\n",
    "        # Group the data by country and calculate the first quartile of the column\n",
    "        first_quartile_by_country = round(df.groupby(\"prop_country_id\")[column].quantile(0.25))\n",
    "        # Fill missing values in the column with the first quartile of the respective country\n",
    "        df[column].fillna(df[\"prop_country_id\"].map(first_quartile_by_country), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define a list of columns to fill missing values for\n",
    "columns_to_fill = ['visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_review_score', 'prop_location_score2',\n",
    "                   'srch_query_affinity_score', 'orig_destination_distance', 'comp1_rate', 'comp1_inv', \n",
    "                   'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv', 'comp2_rate_percent_diff', 'comp3_rate', \n",
    "                   'comp3_inv', 'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv', 'comp4_rate_percent_diff', \n",
    "                   'comp5_rate', 'comp5_inv', 'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "                   'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv', 'comp7_rate_percent_diff',\n",
    "                   'comp8_rate', 'comp8_inv', 'comp8_rate_percent_diff']\n",
    "\n",
    "new_df = fill_missing_values_with_first_quartile(cleaned_df,columns_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srch_id                              0\n",
       "date_time                            0\n",
       "site_id                              0\n",
       "visitor_location_country_id          0\n",
       "visitor_hist_starrating           2710\n",
       "visitor_hist_adr_usd              2710\n",
       "prop_country_id                      0\n",
       "prop_id                              0\n",
       "prop_starrating                      0\n",
       "prop_review_score                    0\n",
       "prop_brand_bool                      0\n",
       "prop_location_score1                 0\n",
       "prop_location_score2                 2\n",
       "prop_log_historical_price            0\n",
       "position                             0\n",
       "price_usd                            0\n",
       "promotion_flag                       0\n",
       "srch_destination_id                  0\n",
       "srch_length_of_stay                  0\n",
       "srch_booking_window                  0\n",
       "srch_adults_count                    0\n",
       "srch_children_count                  0\n",
       "srch_room_count                      0\n",
       "srch_saturday_night_bool             0\n",
       "srch_query_affinity_score        20516\n",
       "orig_destination_distance          150\n",
       "random_bool                          0\n",
       "comp1_rate                     1213315\n",
       "comp1_inv                      1213315\n",
       "comp1_rate_percent_diff        1213315\n",
       "comp2_rate                      354693\n",
       "comp2_inv                       148609\n",
       "comp2_rate_percent_diff         384703\n",
       "comp3_rate                      152227\n",
       "comp3_inv                       143774\n",
       "comp3_rate_percent_diff         175447\n",
       "comp4_rate                      605133\n",
       "comp4_inv                       576158\n",
       "comp4_rate_percent_diff         606353\n",
       "comp5_rate                        3046\n",
       "comp5_inv                         3046\n",
       "comp5_rate_percent_diff           3066\n",
       "comp6_rate                      889743\n",
       "comp6_inv                       857985\n",
       "comp6_rate_percent_diff         889772\n",
       "comp7_rate                      891867\n",
       "comp7_inv                       891867\n",
       "comp7_rate_percent_diff         905013\n",
       "comp8_rate                      244799\n",
       "comp8_inv                       225659\n",
       "comp8_rate_percent_diff         431808\n",
       "click_bool                           0\n",
       "gross_bookings_usd             4817066\n",
       "booking_bool                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srch_id                         0\n",
       "date_time                       0\n",
       "site_id                         0\n",
       "visitor_location_country_id     0\n",
       "visitor_hist_starrating         0\n",
       "visitor_hist_adr_usd            0\n",
       "prop_country_id                 0\n",
       "prop_id                         0\n",
       "prop_starrating                 0\n",
       "prop_review_score               0\n",
       "prop_brand_bool                 0\n",
       "prop_location_score1            0\n",
       "prop_location_score2            0\n",
       "prop_log_historical_price       0\n",
       "position                        0\n",
       "price_usd                       0\n",
       "promotion_flag                  0\n",
       "srch_destination_id             0\n",
       "srch_length_of_stay             0\n",
       "srch_booking_window             0\n",
       "srch_adults_count               0\n",
       "srch_children_count             0\n",
       "srch_room_count                 0\n",
       "srch_saturday_night_bool        0\n",
       "srch_query_affinity_score       0\n",
       "orig_destination_distance       0\n",
       "random_bool                     0\n",
       "comp1_rate                      0\n",
       "comp1_inv                       0\n",
       "comp1_rate_percent_diff         0\n",
       "comp2_rate                      0\n",
       "comp2_inv                       0\n",
       "comp2_rate_percent_diff         0\n",
       "comp3_rate                      0\n",
       "comp3_inv                       0\n",
       "comp3_rate_percent_diff         0\n",
       "comp4_rate                      0\n",
       "comp4_inv                       0\n",
       "comp4_rate_percent_diff         0\n",
       "comp5_rate                      0\n",
       "comp5_inv                       0\n",
       "comp5_rate_percent_diff         0\n",
       "comp6_rate                      0\n",
       "comp6_inv                       0\n",
       "comp6_rate_percent_diff         0\n",
       "comp7_rate                      0\n",
       "comp7_inv                       0\n",
       "comp7_rate_percent_diff         0\n",
       "comp8_rate                      0\n",
       "comp8_inv                       0\n",
       "comp8_rate_percent_diff         0\n",
       "click_bool                      0\n",
       "gross_bookings_usd             12\n",
       "booking_bool                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill the missing values with forward filling method \n",
    "new_df = new_df.fillna(method='ffill')\n",
    "# check if still some missing values\n",
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the features still have a lot of missing values\n",
    "new_df=new_df.drop(['gross_bookings_usd'],axis=1)\n",
    "# new_df=new_df.drop(['comp6_rate','comp6_inv','comp6_rate_percent_diff','gross_bookings_usd'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4955367, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>log_price_diff</th>\n",
       "      <th>star_rank</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>location_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.288733</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-26.137525</td>\n",
       "      <td>2.8738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.115982</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.189522</td>\n",
       "      <td>2.2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.277391</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.892475</td>\n",
       "      <td>2.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-2.013193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>517.518263</td>\n",
       "      <td>2.8425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.043833</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-66.349522</td>\n",
       "      <td>2.7641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  visitor_hist_starrating  \\\n",
       "0        1       12                          187                      3.0   \n",
       "1        1       12                          187                      3.0   \n",
       "2        1       12                          187                      3.0   \n",
       "3        1       12                          187                      3.0   \n",
       "4        1       12                          187                      3.0   \n",
       "\n",
       "   visitor_hist_adr_usd  prop_country_id  prop_id  prop_starrating  \\\n",
       "0                 101.0              219      893                3   \n",
       "1                 101.0              219    10404                4   \n",
       "2                 101.0              219    21315                3   \n",
       "3                 101.0              219    27348                2   \n",
       "4                 101.0              219    29604                4   \n",
       "\n",
       "   prop_review_score  prop_brand_bool  ...  click_bool  booking_bool  year  \\\n",
       "0                3.5                1  ...           0             0  2013   \n",
       "1                4.0                1  ...           0             0  2013   \n",
       "2                4.5                1  ...           0             0  2013   \n",
       "3                4.0                1  ...           0             0  2013   \n",
       "4                3.5                1  ...           0             0  2013   \n",
       "\n",
       "   month  day  hour  log_price_diff  star_rank  price_diff  location_score  \n",
       "0      4    4     8        0.288733        3.0  -26.137525          2.8738  \n",
       "1      4    4     8       -0.115982        2.0  -39.189522          2.2149  \n",
       "2      4    4     8       -0.277391        3.0   48.892475          2.2245  \n",
       "3      4    4     8       -2.013193        4.0  517.518263          2.8425  \n",
       "4      4    4     8       -0.043833        2.0  -66.349522          2.7641  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features engineer\n",
    "data = new_df\n",
    "# convert date_time to year, month, day, and hour\n",
    "data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "data['year'] = data['date_time'].dt.year\n",
    "data['month'] = data['date_time'].dt.month\n",
    "data['day'] = data['date_time'].dt.day\n",
    "data['hour'] = data['date_time'].dt.hour\n",
    "data = data.drop('date_time', axis=1)\n",
    "\n",
    "# create new features\n",
    "data['log_price_diff'] = data['prop_log_historical_price'] - np.log(data['price_usd']+1)\n",
    "\n",
    "data['star_rank'] = data.groupby('visitor_location_country_id')['prop_starrating'].rank(method='dense', ascending=False)\n",
    "\n",
    "# Calculate average price by country and star rating\n",
    "avg_price = data.groupby(['prop_country_id', 'prop_starrating'])['price_usd'].transform('mean')\n",
    "# Calculate price difference and Add price difference as a new feature\n",
    "data['price_diff'] = data['price_usd'] - avg_price\n",
    "\n",
    "\n",
    "# To combine the prop_location_score1 and prop_location_score2 columns to create a new feature that captures \n",
    "# the overall location score of the hotel, we can simply add these two columns\n",
    "data['location_score'] = data['prop_location_score1'] + data['prop_location_score2']\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test_set_VU_DM.csv', nrows=100 )#, skiprows=range(1, 4400000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a subset of the training data similar to the query \n",
    "def subset_of_data(data,\n",
    "                   prop_country_id,\n",
    "                   srch_destination_id,\n",
    "                   srch_length_of_stay=None,\n",
    "                   srch_room_count=None,\n",
    "                   srch_adults_count=None,\n",
    "                   srch_children_count= None):    \n",
    "    \n",
    "    new_df = data[data['prop_country_id'] == prop_country_id]\n",
    "    new_df1 = new_df[new_df['srch_destination_id'] == srch_destination_id]\n",
    "    new_df2 = new_df1[new_df1['srch_length_of_stay'] == srch_length_of_stay]\n",
    "    new_df3 = new_df2[new_df2['srch_room_count'] == srch_room_count]\n",
    "    new_df4 = new_df3[new_df3['srch_adults_count'] == srch_adults_count]\n",
    "    new_df5= new_df4[new_df4['srch_children_count'] == srch_children_count]\n",
    "    return new_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_matrix(new_df,instance):    \n",
    "    # Concatenate the dataframes vertically (along the rows)\n",
    "    new_df = pd.concat([new_df, instance], axis=0)\n",
    "    # Get unique prop_id values\n",
    "    unique_props = new_df['prop_id'].unique()\n",
    "\n",
    "    # Create a new DataFrame with prop_id as columns and srch_id as index\n",
    "    matrix = pd.DataFrame(0, index=new_df['srch_id'].unique(), columns=unique_props)\n",
    "\n",
    "    # Fill the matrix with the interaction or rating values\n",
    "    for _, row in new_df.iterrows():\n",
    "        srch_id = row['srch_id']\n",
    "        prop_id = row['prop_id']\n",
    "    # rating1 = row['click_bool']  # You can define your own rating metric\n",
    "        rating = row['click_bool'] + 10 * row['booking_bool'] - (row['price_usd'] / new_df['price_usd'].max()) +\\\n",
    "        + row['prop_review_score']-3 - row['promotion_flag']\n",
    "        \n",
    "        matrix.loc[srch_id, prop_id] = rating\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_sort(matrix):\n",
    "    matrix1 = matrix.sum(axis=0)\n",
    "    sorted_values = matrix1.sort_values(ascending=False)\n",
    "    return sorted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance(data,srch_id):\n",
    "    instance = data[data['srch_id'] == srch_id].reset_index(drop=True)\n",
    "    return instance\n",
    "# instance = get_instance(test_set,srch_id=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result-1.csv\", \"w+\") as file:\n",
    "    file.write(\"srch_id,prop_id\")\n",
    "    \n",
    "    for inst in test_set['srch_id'].unique():\n",
    "        instance = get_instance(test_set,srch_id=inst)\n",
    "        reco_hotel = None\n",
    "        for i, row in instance.iterrows():\n",
    "            test = subset_of_data(data= data,\n",
    "                                  prop_country_id= row['prop_country_id'],\n",
    "                                  srch_destination_id= row[\"srch_destination_id\"],\n",
    "                                  srch_length_of_stay= row['srch_length_of_stay'],\n",
    "                                   srch_room_count= row['srch_room_count'],\n",
    "                                 srch_adults_count= row['srch_adults_count'],\n",
    "                                 srch_children_count= row['srch_children_count']\n",
    "                                 )\n",
    "            matrix = create_train_matrix(test,instance)\n",
    "            reco_hotel = sum_sort(matrix)\n",
    "            reco_hotel = (reco_hotel.index)\n",
    "            break\n",
    "\n",
    "        for i in range(len(instance)):\n",
    "            \n",
    "            file.write(f\"\\n{inst},{reco_hotel[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'site_id', 'visitor_location_country_id',\n",
       "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
       "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
       "       'prop_location_score1', 'prop_location_score2',\n",
       "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
       "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
       "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
       "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
       "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
       "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
       "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
       "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
       "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
       "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
       "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
       "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
       "       'comp8_rate_percent_diff', 'click_bool', 'booking_bool', 'year',\n",
       "       'month', 'day', 'hour', 'log_price_diff', 'star_rank', 'price_diff',\n",
       "       'location_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['prop_location_score2', 'price_usd', 'promotion_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# df = pd.read_csv(\"/kaggle/input/vu-dmt-assigment-2-2023/training_set_VU_DM.csv\")\n",
    "target = 'booking_bool'\n",
    "train_df, val_df = train_test_split(data, test_size=0.2)\n",
    "lgb_train = lgb.Dataset(train_df[features], label=train_df[target], group=train_df.groupby('srch_id').size())\n",
    "\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [5],\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "val_pred = gbm.predict(val_df[features])\n",
    "val_labels = val_df[target]\n",
    "ndcg = ndcg_score([val_pred], [val_labels], k=5)\n",
    "print(\"NDCG@5:\", ndcg)\n",
    "\n",
    "\n",
    "def create_submission_file():\n",
    "    test_df = pd.read_csv(\"data/test_set_VU_DM.csv\")\n",
    "    test_pred = gbm.predict(test_df[features])\n",
    "    properties_to_rank = test_df[['srch_id', 'prop_id', 'prop_location_score2', 'price_usd', 'promotion_flag']].copy()\n",
    "    properties_to_rank[\"score\"] = test_pred\n",
    "    aggregated_scores = properties_to_rank.groupby(['srch_id', 'prop_id'])['score'].mean().reset_index()\n",
    "    ranked_properties = aggregated_scores.sort_values(['srch_id', 'score'], ascending=[True, False])\n",
    "\n",
    "    file = open(\"result-2.csv\", \"w+\")\n",
    "    file.write(\"srch_id,prop_id\")\n",
    "    for srch_id, group in ranked_properties.groupby('srch_id'):\n",
    "        for i, row in group.iterrows():\n",
    "            file.write(f\"\\n{srch_id},{int(row['prop_id'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
